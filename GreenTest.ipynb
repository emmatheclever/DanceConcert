{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b55a563",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9dc711d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['7.mp4', '6.mp4', '4.mp4', '5.mp4', '1.mp4', '2.mp4', '3.mp4', '16.mp4', '14.mp4', '15.mp4', '11.mp4', '10.mp4', '12.mp4', '13.mp4', '8.mp4', '9.mp4']\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "# Collecting dance files and setting test constants\n",
    "data_path = \"/Users/emmawaters/Desktop/Dance/greenTest/\"\n",
    "vid_names = []\n",
    "dir_list = os.listdir(data_path)\n",
    "for i in dir_list:\n",
    "    if i.endswith(\".mp4\"):\n",
    "        vid_names.append(i)\n",
    "\n",
    "NUM_FRAMES = float('inf')\n",
    "NUM_PARTS = 15\n",
    "NUM_TIME_CHUNKS = 5\n",
    "NUM_VIDS = len(vid_names)\n",
    "print(vid_names)\n",
    "print(NUM_VIDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a92a172",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_video_to_movement(vidpath):\n",
    "    data = []\n",
    "    net = cv.dnn.readNetFromTensorflow(\"graph_opt.pb\")\n",
    "    cap = cv.VideoCapture(vidpath)\n",
    "\n",
    "    BODY_PARTS = { \"Nose\": 0, \"Neck\": 1, \"RShoulder\": 2, \"RElbow\": 3, \"RWrist\": 4,\n",
    "                   \"LShoulder\": 5, \"LElbow\": 6, \"LWrist\": 7, \"RHip\": 8, \"RKnee\": 9,\n",
    "                   \"RAnkle\": 10, \"LHip\": 11, \"LKnee\": 12, \"LAnkle\": 13, \"Background\": 14 }\n",
    "\n",
    "    POSE_PAIRS = [ [\"Neck\", \"RShoulder\"], [\"Neck\", \"LShoulder\"], [\"RShoulder\", \"RElbow\"],\n",
    "                   [\"RElbow\", \"RWrist\"], [\"LShoulder\", \"LElbow\"], [\"LElbow\", \"LWrist\"],\n",
    "                   [\"Neck\", \"RHip\"], [\"RHip\", \"RKnee\"], [\"RKnee\", \"RAnkle\"], [\"Neck\", \"LHip\"],\n",
    "                   [\"LHip\", \"LKnee\"], [\"LKnee\", \"LAnkle\"], [\"Neck\", \"Nose\"] ]\n",
    "\n",
    "    error = 0\n",
    "    while cv.waitKey(1) < 0:\n",
    "        hasFrame, frame = cap.read()\n",
    "        if not hasFrame:\n",
    "            break\n",
    "\n",
    "        #frame = cv.rotate(frame, cv.ROTATE_180) #ONLY needed if raw iPhone data\n",
    "        frameWidth = frame.shape[1]\n",
    "        frameHeight = frame.shape[0]\n",
    "        net.setInput(cv.dnn.blobFromImage(frame, 1.0, (368, 368), (127.5, 127.5, 127.5), swapRB=True, crop=False))\n",
    "        out = net.forward()\n",
    "        out = out[:, :15, :, :]\n",
    "\n",
    "        assert(len(BODY_PARTS) == out.shape[1])\n",
    "\n",
    "        points = []\n",
    "        for i in range(len(BODY_PARTS)):\n",
    "            heatMap = out[0, i, :, :]\n",
    "            _, conf, _, point = cv.minMaxLoc(heatMap)\n",
    "            x = (frameWidth * point[0]) / out.shape[3]\n",
    "            y = (frameHeight * point[1]) / out.shape[2]\n",
    "            if conf > 0.1:\n",
    "                points.append(np.array([x, y]))\n",
    "            else:\n",
    "                points.append(np.array([None,None]))\n",
    "                error += 1\n",
    "\n",
    "        data.append(points)\n",
    "        \n",
    "        for pair in POSE_PAIRS:\n",
    "            partFrom = pair[0]\n",
    "            partTo = pair[1]\n",
    "            assert(partFrom in BODY_PARTS)\n",
    "            assert(partTo in BODY_PARTS)\n",
    "\n",
    "            idFrom = BODY_PARTS[partFrom]\n",
    "            idTo = BODY_PARTS[partTo]\n",
    "\n",
    "            if points[idFrom].any() and points[idTo].any():\n",
    "                cv.line(frame, [int(points[idFrom][0]), int(points[idFrom][1])], [int(points[idTo][0]), int(points[idTo][1])], (0, 255, 0), 3)\n",
    "                cv.ellipse(frame, [int(points[idFrom][0]), int(points[idFrom][1])], (3, 3), 0, 0, 360, (0, 0, 255), cv.FILLED)\n",
    "                cv.ellipse(frame, [int(points[idTo][0]), int(points[idTo][1])], (3, 3), 0, 0, 360, (0, 0, 255), cv.FILLED)\n",
    "\n",
    "        t, _ = net.getPerfProfile()\n",
    "        freq = cv.getTickFrequency() / 1000\n",
    "        cv.putText(frame, '%.2fms' % (t / freq), (10, 20), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0))\n",
    "\n",
    "        cv.imshow('OpenPose using OpenCV', frame)\n",
    "\n",
    "    cv.destroyWindow('OpenPose using OpenCV')\n",
    "        \n",
    "    return (data, error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb94aa56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/cm/7hq47gqs3jg9z0cbwr6pwggm0000gn/T/ipykernel_61599/254514155.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvid_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0mmovement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_video_to_movement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvid_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mmovement_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mvid_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/cm/7hq47gqs3jg9z0cbwr6pwggm0000gn/T/ipykernel_61599/1931559189.py\u001b[0m in \u001b[0;36mread_video_to_movement\u001b[0;34m(vidpath)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mframeHeight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblobFromImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m368\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m368\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m127.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m127.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m127.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswapRB\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Collect movements in a list, calculate number of missed joints\n",
    "movement_list = []\n",
    "total_missed = 0\n",
    "total_frames = 0\n",
    "\n",
    "for i in range(len(vid_names)):\n",
    "    print(i)\n",
    "    (movement, missed) = read_video_to_movement(data_path + vid_names[i])\n",
    "    movement_list.append(movement)\n",
    "    vid_frames = len(movement)\n",
    "    total_missed += missed\n",
    "    total_frames += vid_frames\n",
    "    if vid_frames < NUM_FRAMES:\n",
    "        NUM_FRAMES = vid_frames\n",
    "        \n",
    "# Compare number of missed joints to the number of expected joints\n",
    "expected_num_joints = vid_frames * 15 * NUM_VIDS\n",
    "error_factor = total_missed/expected_num_joints\n",
    "print(error_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fd286c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
