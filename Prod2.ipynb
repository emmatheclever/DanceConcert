{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80433ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "\n",
    "PARENT_DIR = \"/Users/emmawaters/Desktop/Dance/Prod/\"\n",
    "NUM_PARTS = 15\n",
    "NUM_CHUNKS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5155da08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR COLOR CODING THE NOTEBOOK\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "def set_background(color):    \n",
    "    script = (\n",
    "        \"var cell = this.closest('.jp-CodeCell');\"\n",
    "        \"var editor = cell.querySelector('.jp-Editor');\"\n",
    "        \"editor.style.background='{}';\"\n",
    "        \"this.parentNode.removeChild(this)\"\n",
    "    ).format(color)\n",
    "    \n",
    "    display(HTML('<img src onerror=\"{}\" style=\"display:none\">'.format(script)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c4bf14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_video_to_movement returns the list of joint positions found using openCV\n",
    "# Also returns a count of the number of joints not found, to be used to measure accuracy\n",
    "\n",
    "def read_video_to_movement(vidpath):\n",
    "    data = []\n",
    "    net = cv.dnn.readNetFromTensorflow(\"graph_opt.pb\")\n",
    "    cap = cv.VideoCapture(vidpath)\n",
    "\n",
    "    BODY_PARTS = { \"Nose\": 0, \"Neck\": 1, \"RShoulder\": 2, \"RElbow\": 3, \"RWrist\": 4,\n",
    "                   \"LShoulder\": 5, \"LElbow\": 6, \"LWrist\": 7, \"RHip\": 8, \"RKnee\": 9,\n",
    "                   \"RAnkle\": 10, \"LHip\": 11, \"LKnee\": 12, \"LAnkle\": 13, \"Background\": 14 }\n",
    "\n",
    "    POSE_PAIRS = [ [\"Neck\", \"RShoulder\"], [\"Neck\", \"LShoulder\"], [\"RShoulder\", \"RElbow\"],\n",
    "                   [\"RElbow\", \"RWrist\"], [\"LShoulder\", \"LElbow\"], [\"LElbow\", \"LWrist\"],\n",
    "                   [\"Neck\", \"RHip\"], [\"RHip\", \"RKnee\"], [\"RKnee\", \"RAnkle\"], [\"Neck\", \"LHip\"],\n",
    "                   [\"LHip\", \"LKnee\"], [\"LKnee\", \"LAnkle\"], [\"Neck\", \"Nose\"] ]\n",
    "\n",
    "    error = 0\n",
    "    while cv.waitKey(1) < 0:\n",
    "        hasFrame, frame = cap.read()\n",
    "        if not hasFrame:\n",
    "            break\n",
    "\n",
    "        #frame = cv.rotate(frame, cv.ROTATE_180) #ONLY needed if raw iPhone data\n",
    "        frameWidth = frame.shape[1]\n",
    "        frameHeight = frame.shape[0]\n",
    "        net.setInput(cv.dnn.blobFromImage(frame, 1.0, (368, 368), (127.5, 127.5, 127.5), swapRB=True, crop=False))\n",
    "        out = net.forward()\n",
    "        out = out[:, :15, :, :]\n",
    "\n",
    "        assert(len(BODY_PARTS) == out.shape[1])\n",
    "\n",
    "        points = []\n",
    "        for i in range(len(BODY_PARTS)):\n",
    "            heatMap = out[0, i, :, :]\n",
    "            _, conf, _, point = cv.minMaxLoc(heatMap)\n",
    "            x = (frameWidth * point[0]) / out.shape[3]\n",
    "            y = (frameHeight * point[1]) / out.shape[2]\n",
    "            if conf > 0.1:\n",
    "                points.append(np.array([x, y]))\n",
    "            else:\n",
    "                points.append(np.array([None,None]))\n",
    "                error += 1\n",
    "\n",
    "        data.append(points)\n",
    "    return (data, error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ab2ef1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10eb8150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLLECT VIDEOS\n",
    "\n",
    "song_list = ['Aurora', 'Aphex', 'Armatrading', 'Tnertle', 'Willow', 'Jiggle']\n",
    "dancer_list = ['Dorissa', 'Dot', 'Falcon', 'Imogen', 'Lia', 'Sophia', 'Sunny']\n",
    "vid_names = []\n",
    "dir_list = os.listdir(PARENT_DIR)\n",
    "for i in dir_list:\n",
    "    if i.endswith(\".mp4\"):\n",
    "        vid_names.append(i)\n",
    "        \n",
    "raw_name_dict = {'Aurora':[], 'Aphex':[], 'Armatrading':[], 'Tnertle':[], 'Willow':[], 'Jiggle':[]}\n",
    "for vid in vid_names:\n",
    "    name_split = vid.split('.')[0].split('_')\n",
    "    raw_name_dict[name_split[1]].append(vid)\n",
    "\n",
    "for i in raw_name_dict:\n",
    "    raw_name_dict[i].sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a40fb3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time.struct_time(tm_year=2023, tm_mon=3, tm_mday=8, tm_hour=17, tm_min=46, tm_sec=0, tm_wday=2, tm_yday=67, tm_isdst=0)\n",
      "Aurora\n",
      "Dorissa_Aurora.mp4\n",
      "Dot_Aurora.mp4\n",
      "Falcon_Aurora.mp4\n",
      "Imogen_Aurora.mp4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/cm/7hq47gqs3jg9z0cbwr6pwggm0000gn/T/ipykernel_22512/3610267481.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdancer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_name_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msong\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdancer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mmovement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_video_to_movement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPARENT_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdancer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0merrors_by_dance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msong\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mNUM_PARTS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0msong_raw_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/cm/7hq47gqs3jg9z0cbwr6pwggm0000gn/T/ipykernel_22512/1588738244.py\u001b[0m in \u001b[0;36mread_video_to_movement\u001b[0;34m(vidpath)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mframeHeight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblobFromImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m368\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m368\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m127.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m127.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m127.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswapRB\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# COLLECT RAW MOTION TRACKING DATA AND COLLECT ERRORS\n",
    "FRAMES_BY_SONG = {}\n",
    "raw_dance_data = {}\n",
    "errors_by_dance = {'Aurora':[], 'Aphex':[], 'Armatrading':[], 'Tnertle':[], 'Willow':[], 'Jiggle':[]}\n",
    "\n",
    "print(time.gmtime())\n",
    "\n",
    "for song in song_list:\n",
    "    print(song)\n",
    "    num_frames = float('inf')\n",
    "    song_raw_data = []\n",
    "    for dancer in raw_name_dict[song]:\n",
    "        print(dancer)\n",
    "        (movement, error) = read_video_to_movement(os.path.join(PARENT_DIR, dancer))\n",
    "        errors_by_dance[song].append(error/(len(movement)*NUM_PARTS))\n",
    "        song_raw_data.append(movement)\n",
    "        if len(movement) < num_frames:\n",
    "            num_frames = len(movement)\n",
    "    \n",
    "    FRAMES_BY_SONG[song] = num_frames\n",
    "    raw_dance_data[song] = song_raw_data  \n",
    "\n",
    "print(time.gmtime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6637f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPUTE CHARACTERISTIC VECTORS PER DANCE\n",
    "\n",
    "def vectorize_movement(movement, num_chunks, NUM_PARTS, NUM_FRAMES):\n",
    "    move_vec = []\n",
    "    chunk_size = int(NUM_FRAMES/num_chunks)\n",
    "    for n in range(num_chunks):\n",
    "        for joint in range(NUM_PARTS):\n",
    "            x_pos_disp = 0\n",
    "            x_neg_disp = 0\n",
    "            y_pos_disp = 0\n",
    "            y_neg_disp = 0\n",
    "\n",
    "            for i in range(chunk_size - 1):\n",
    "                prev_frame = movement[n*chunk_size + i]\n",
    "                frame = movement[n*chunk_size + i + 1]\n",
    "\n",
    "                if prev_frame[joint].all() and frame[joint].all():\n",
    "                    disp = prev_frame[joint] - frame[joint]\n",
    "\n",
    "                    if disp[0] > 0:\n",
    "                        x_pos_disp += disp[0]\n",
    "                    else:\n",
    "                        x_neg_disp += disp[0]\n",
    "                    if disp[1] > 0:\n",
    "                        y_pos_disp += disp[1]\n",
    "                    else:\n",
    "                        y_neg_disp += disp[1]\n",
    "            move_vec += [x_pos_disp, x_neg_disp, y_pos_disp, y_neg_disp]\n",
    "    return move_vec\n",
    "\n",
    "characteristic_vectors = {}\n",
    "for song in song_list:\n",
    "    characteristic_vectors[song] = []\n",
    "    for raw_motion in raw_dance_data[song]:\n",
    "        move_vec = vectorize_movement(raw_motion, NUM_CHUNKS, NUM_PARTS, FRAMES_BY_SONG[song])\n",
    "        characteristic_vectors[song].append(np.array(move_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deff3c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMBINE VECTORS INTO A DATAFRAME\n",
    "X_dict = {}\n",
    "for song in song_list:\n",
    "    X = np.array(characteristic_vectors[song])\n",
    "    \n",
    "    X_scaled = StandardScaler().fit_transform(X)\n",
    "    X_dict[song] = X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c82156d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRODUCING PLOTS\n",
    "\n",
    "def show_scree(song, X):\n",
    "    pca_7comp = PCA(n_components=7)\n",
    "    pca_7fit = pca_7comp.fit(X)\n",
    "\n",
    "    plt.bar(\n",
    "        range(1,len(pca_7comp.explained_variance_ratio_)+1),\n",
    "        pca_7comp.explained_variance_ratio_\n",
    "        )\n",
    "    plt.xlabel('PCA Feature')\n",
    "    plt.ylabel('Explained variance')\n",
    "    plt.title('Feature Explained Variance ' + song)\n",
    "    plt.show()\n",
    "    print(pca_7comp.explained_variance_ratio_)\n",
    "\n",
    "def show_pca_2plot(song, X):\n",
    "    pca_2comp = PCA(n_components=2)\n",
    "    pca_2fit = pca_2comp.fit_transform(X)\n",
    "    \n",
    "    pca_df = pd.DataFrame(data=pca_2fit, columns=['PC1', 'PC2'])\n",
    "    pca_df['target'] = ['Dorissa', 'Dot', 'Falcon', 'Imogen', 'Lia', 'Sophia', 'Sunny']\n",
    "    \n",
    "    sns.set()\n",
    "    sns.lmplot(\n",
    "        x='PC1', \n",
    "        y='PC2', \n",
    "        data=pca_df, \n",
    "        hue='target', \n",
    "        fit_reg=False, \n",
    "        legend=True\n",
    "        )\n",
    "\n",
    "    plt.title(song)\n",
    "    plt.show()\n",
    "    \n",
    "# GENERATE PCA TABLES & PLOTS\n",
    "for song in song_list:\n",
    "    show_scree(song, X_dict[song])\n",
    "    show_pca_2plot(song, X_dict[song])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cad5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(errors_by_dance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982b9203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ERROR AVERAGING\n",
    "set_background('red')\n",
    "\n",
    "for song in song_list:\n",
    "    sum_errors = 0\n",
    "    for error in errors_by_dance[song]:\n",
    "        sum_errors += error\n",
    "    avg_error = sum_errors/7\n",
    "    print(song + \": \" + str(avg_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ea9b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VALIDATION DATA\n",
    "set_background('red')\n",
    "\n",
    "for song in song_list:\n",
    "    distances_by_dancer = {} # \"name\":(dis charactersitic, dist pca)\n",
    "    for dancer in dancer_list:\n",
    "        for comp_dancer in dancer_list:\n",
    "            dist_char = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6b6be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA PER DANCER (OG IMPROV VIDS)\n",
    "set_background('yellow')\n",
    "char_vectors_by_dancer = [['Dorissa', []], ['Dot',[]], ['Falcon',[]], ['Imogen',[]], ['Lia',[]], ['Sophia',[]], ['Sunny',[]]]\n",
    "for song in song_list:\n",
    "    for i in range(7):\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
