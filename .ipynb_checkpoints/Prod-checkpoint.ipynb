{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e69c3499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec715d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_video_to_movement returns the list of joint positions found using openCV\n",
    "# Also returns a count of the number of joints not found, to be used to measure accuracy\n",
    "\n",
    "def read_video_to_movement(vidpath):\n",
    "    data = []\n",
    "    net = cv.dnn.readNetFromTensorflow(\"graph_opt.pb\")\n",
    "    cap = cv.VideoCapture(vidpath)\n",
    "\n",
    "    BODY_PARTS = { \"Nose\": 0, \"Neck\": 1, \"RShoulder\": 2, \"RElbow\": 3, \"RWrist\": 4,\n",
    "                   \"LShoulder\": 5, \"LElbow\": 6, \"LWrist\": 7, \"RHip\": 8, \"RKnee\": 9,\n",
    "                   \"RAnkle\": 10, \"LHip\": 11, \"LKnee\": 12, \"LAnkle\": 13, \"Background\": 14 }\n",
    "\n",
    "    POSE_PAIRS = [ [\"Neck\", \"RShoulder\"], [\"Neck\", \"LShoulder\"], [\"RShoulder\", \"RElbow\"],\n",
    "                   [\"RElbow\", \"RWrist\"], [\"LShoulder\", \"LElbow\"], [\"LElbow\", \"LWrist\"],\n",
    "                   [\"Neck\", \"RHip\"], [\"RHip\", \"RKnee\"], [\"RKnee\", \"RAnkle\"], [\"Neck\", \"LHip\"],\n",
    "                   [\"LHip\", \"LKnee\"], [\"LKnee\", \"LAnkle\"], [\"Neck\", \"Nose\"] ]\n",
    "\n",
    "    error = 0\n",
    "    while cv.waitKey(1) < 0:\n",
    "        hasFrame, frame = cap.read()\n",
    "        if not hasFrame:\n",
    "            break\n",
    "\n",
    "        #frame = cv.rotate(frame, cv.ROTATE_180) #ONLY needed if raw iPhone data\n",
    "        frameWidth = frame.shape[1]\n",
    "        frameHeight = frame.shape[0]\n",
    "        net.setInput(cv.dnn.blobFromImage(frame, 1.0, (368, 368), (127.5, 127.5, 127.5), swapRB=True, crop=False))\n",
    "        out = net.forward()\n",
    "        out = out[:, :15, :, :]\n",
    "\n",
    "        assert(len(BODY_PARTS) == out.shape[1])\n",
    "\n",
    "        points = []\n",
    "        for i in range(len(BODY_PARTS)):\n",
    "            heatMap = out[0, i, :, :]\n",
    "            _, conf, _, point = cv.minMaxLoc(heatMap)\n",
    "            x = (frameWidth * point[0]) / out.shape[3]\n",
    "            y = (frameHeight * point[1]) / out.shape[2]\n",
    "            if conf > 0.1:\n",
    "                points.append(np.array([x, y]))\n",
    "            else:\n",
    "                points.append(np.array([None,None]))\n",
    "                error += 1\n",
    "\n",
    "        data.append(points)\n",
    "    return (data, error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4954c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect movements in a list, calculate number of missed joints\n",
    "def generate_movement_list(vid_names, data_path):\n",
    "    movement_list = []\n",
    "    total_missed = 0\n",
    "    NUM_FRAMES = float('inf')\n",
    "\n",
    "    for i in range(len(vid_names)):\n",
    "        print(i) # Cheap Status Bar\n",
    "        (movement, missed) = read_video_to_movement(data_path + vid_names[i])\n",
    "        movement_list.append(movement)\n",
    "        vid_frames = len(movement)\n",
    "        total_missed += missed\n",
    "        if vid_frames < NUM_FRAMES:\n",
    "            NUM_FRAMES = vid_frames\n",
    "        print(NUM_FRAMES)\n",
    "\n",
    "    # Compare number of missed joints to the number of expected joints\n",
    "    expected_num_joints = NUM_FRAMES * 15 * NUM_VIDS\n",
    "    error_factor = total_missed/expected_num_joints\n",
    "    return(movement_list, error_factor, NUM_FRAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "610147b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize_movement transforms a movement into a characteristic vector\n",
    "# A higher value for num_chunks increases the resolution of the characteristics\n",
    "\n",
    "def vectorize_movement(movement, num_chunks, NUM_PARTS, NUM_FRAMES):\n",
    "    move_vec = []\n",
    "    chunk_size = int(NUM_FRAMES/num_chunks)\n",
    "    for n in range(num_chunks):\n",
    "        for joint in range(NUM_PARTS):\n",
    "            x_pos_disp = 0\n",
    "            x_neg_disp = 0\n",
    "            y_pos_disp = 0\n",
    "            y_neg_disp = 0\n",
    "\n",
    "            for i in range(chunk_size - 1):\n",
    "                prev_frame = movement[n*chunk_size + i]\n",
    "                frame = movement[n*chunk_size + i + 1]\n",
    "\n",
    "                if prev_frame[joint].all() and frame[joint].all():\n",
    "                    disp = prev_frame[joint] - frame[joint]\n",
    "\n",
    "                    if disp[0] > 0:\n",
    "                        x_pos_disp += disp[0]\n",
    "                    else:\n",
    "                        x_neg_disp += disp[0]\n",
    "                    if disp[1] > 0:\n",
    "                        y_pos_disp += disp[1]\n",
    "                    else:\n",
    "                        y_neg_disp += disp[1]\n",
    "            move_vec += [x_pos_disp, x_neg_disp, y_pos_disp, y_neg_disp]\n",
    "\n",
    "    return move_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2dff7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate characteristic vector of each movement\n",
    "def calculate_X(movement_list, NUM_FRAMES, NUM_PARTS):\n",
    "    move_vec_list = []\n",
    "    for i in range(len(movement_list)):     #need to do AFTER determining min num_frames\n",
    "        move_vec = vectorize_movement(movement_list[i][:NUM_FRAMES], 1, NUM_PARTS, NUM_FRAMES)\n",
    "        move_vec_list.append(np.array(move_vec))\n",
    "\n",
    "    # X is the data set we will use for PCA\n",
    "    X = np.array(move_vec_list)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8d6dfc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Aurora': ['Falcon_Aurora.mp4', 'Sunny_Aurora.mp4', 'Dorissa_Aurora.mp4', 'Sophia_Aurora.mp4', 'Imogen_Aurora.mp4', 'Dot_Aurora.mp4', 'Lia_Aurora.mp4'], 'Aphex': ['Dorissa_Aphex.mp4', 'Falcon_Aphex.mp4', 'Dot_Aphex.mp4', 'Sophia_Aphex.mp4', 'Sunny_Aphex.mp4', 'Lia_Aphex.mp4', 'Imogen_Aphex.mp4'], 'Armatrading': ['Sunny_Armatrading.mp4', 'Dorissa_Armatrading.mp4', 'Lia_Armatrading.mp4', 'Imogen_Armatrading.mp4', 'Falcon_Armatrading.mp4', 'Sophia_Armatrading.mp4', 'Dot_Armatrading.mp4'], 'Tnertle': ['Imogen_Tnertle.mp4', 'Lia_Tnertle.mp4', 'Dorissa_Tnertle.mp4', 'Sophia_Tnertle.mp4', 'Sunny_Tnertle.mp4', 'Falcon_Tnertle.mp4', 'Dot_Tnertle.mp4'], 'Willow': ['Sunny_Willow.mp4', 'Falcon_Willow.mp4', 'Sophia_Willow.mp4', 'Dorissa_Willow.mp4', 'Imogen_Willow.mp4', 'Lia_Willow.mp4', 'Dot_Willow.mp4'], 'Jiggle': ['Sunny_Jiggle.mp4', 'Falcon_Jiggle.mp4', 'Sophia_Jiggle.mp4', 'Dorissa_Jiggle.mp4', 'Imogen_Jiggle.mp4', 'Lia_Jiggle.mp4', 'Dot_Jiggle.mp4']}\n"
     ]
    }
   ],
   "source": [
    "# Collecting dance files and setting test constants\n",
    "data_path = \"/Users/emmawaters/Desktop/Dance/Prod/\"\n",
    "song_list = ['Aurora', 'Aphex', 'Armatrading', 'Tnertle', 'Willow', 'Jiggle']\n",
    "vid_names = []\n",
    "dir_list = os.listdir(data_path)\n",
    "for i in dir_list:\n",
    "    if i.endswith(\".mp4\"):\n",
    "        vid_names.append(i)\n",
    "        \n",
    "raw_name_dict = {'Aurora':[], 'Aphex':[], 'Armatrading':[], 'Tnertle':[], 'Willow':[], 'Jiggle':[]}\n",
    "for vid in vid_names:\n",
    "    name_split = vid.split('.')[0].split('_')\n",
    "    raw_name_dict[name_split[1]].append(vid)\n",
    "\n",
    "print(raw_name_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98ab0cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#started @12:42pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60d21e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "820\n",
      "1\n",
      "820\n",
      "2\n",
      "820\n",
      "3\n",
      "812\n",
      "4\n",
      "812\n",
      "5\n",
      "812\n",
      "6\n",
      "812\n",
      "812\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/cm/7hq47gqs3jg9z0cbwr6pwggm0000gn/T/ipykernel_6059/3082580898.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_FRAMES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mdata_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msong\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovement_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_FRAMES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_PARTS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/cm/7hq47gqs3jg9z0cbwr6pwggm0000gn/T/ipykernel_6059/1292166800.py\u001b[0m in \u001b[0;36mcalculate_X\u001b[0;34m(movement_list, NUM_FRAMES, NUM_PARTS)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmove_vec_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_VIDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m     \u001b[0;31m#need to do AFTER determining min num_frames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mmove_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorize_movement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovement_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mNUM_FRAMES\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_PARTS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_FRAMES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mmove_vec_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmove_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "movement_lists = {'Aurora':[], 'Aphex':[], 'Armatrading':[], 'Tnertle':[], 'Willow':[], 'Jiggle':[]}\n",
    "data_dict = {'Aurora':[], 'Aphex':[], 'Armatrading':[], 'Tnertle':[], 'Willow':[], 'Jiggle':[]}\n",
    "errors = []\n",
    "for song in song_list:\n",
    "    NUM_PARTS = 15\n",
    "    NUM_TIME_CHUNKS = 5\n",
    "    NUM_VIDS = len(vid_names)\n",
    "    \n",
    "    (movement_list, error_factor, NUM_FRAMES) = generate_movement_list(raw_name_dict[song], data_path)\n",
    "    movement_lists[song]=movement_list\n",
    "    errors.append(error_factor)\n",
    "    print(NUM_FRAMES)\n",
    "    data_dict[song] = calculate_X(movement_list, NUM_FRAMES, NUM_PARTS)\n",
    "print(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69f2046",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
